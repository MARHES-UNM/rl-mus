{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prime/anaconda3/envs/ray26/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-10-29 00:55:18,505\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2023-10-29 00:55:19,469\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2023-10-29 00:55:19,590\tWARNING deprecation.py:50 -- DeprecationWarning: `DirectStepOptimizer` has been deprecated. This will raise an error in the future!\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "from ray.rllib.algorithms.algorithm import Algorithm\n",
    "import matplotlib.pyplot as plt\n",
    "from ray import tune\n",
    "from uav_sim.envs.uav_sim import UavSim\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-29 00:55:20,030\tWARNING algorithm_config.py:2558 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\n",
      "2023-10-29 00:55:20,031\tWARNING algorithm_config.py:656 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "2023-10-29 00:55:20,032\tWARNING algorithm_config.py:2558 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\n",
      "/home/prime/anaconda3/envs/ray26/lib/python3.9/site-packages/ray/rllib/algorithms/algorithm.py:484: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/home/prime/anaconda3/envs/ray26/lib/python3.9/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/prime/anaconda3/envs/ray26/lib/python3.9/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/prime/anaconda3/envs/ray26/lib/python3.9/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "2023-10-29 00:55:21,699\tINFO worker.py:1621 -- Started a local Ray instance.\n",
      "\u001b[2m\u001b[36m(pid=1348364)\u001b[0m DeprecationWarning: `DirectStepOptimizer` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1348364)\u001b[0m /home/prime/anaconda3/envs/ray26/lib/python3.9/site-packages/gym/spaces/box.py:127: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1348364)\u001b[0m   logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "2023-10-29 00:55:24,811\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2023-10-29 00:55:26,751\tINFO backend_executor.py:138 -- Starting distributed worker processes: ['1348724 (192.168.1.29)']\n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=1348724)\u001b[0m Setting up process group for: env:// [rank=0, world_size=1]\n"
     ]
    }
   ],
   "source": [
    "tune.register_env('multi-uav-sim-v0', lambda config: UavSim(env_config=config))\n",
    "algo = Algorithm.from_checkpoint('/home/prime/Documents/workspace/rl_multi_uav_sim/results/PPO/multi-uav-sim-v0_2023-10-28-22-40_df49a29/low_dt_thresh/PPO_multi-uav-sim-v0_91292_00000_0_beta=0.0100,d_thresh=0.0100,obstacle_collision_weight=1.0000,uav_collision_weight=1.0000,use_sa_2023-10-28_22-40-48/checkpoint_000080')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_policy = algo.get_policy(\"shared_policy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PPOTorchRLModule(\n",
       "  (encoder): TorchActorCriticEncoder(\n",
       "    (actor_encoder): TorchMLPEncoder(\n",
       "      (net): TorchMLP(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=95, out_features=256, bias=True)\n",
       "          (1): Tanh()\n",
       "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (3): Tanh()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (critic_encoder): TorchMLPEncoder(\n",
       "      (net): TorchMLP(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=95, out_features=256, bias=True)\n",
       "          (1): Tanh()\n",
       "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (3): Tanh()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pi): TorchMLPHead(\n",
       "    (net): TorchMLP(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=6, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (vf): TorchMLPHead(\n",
       "    (net): TorchMLP(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shared_policy.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj  = pd.read_pickle('/home/prime/Documents/workspace/rl_multi_uav_sim/results/PPO/multi-uav-sim-v0_2023-10-28-22-40_df49a29/low_dt_thresh/PPO_multi-uav-sim-v0_91292_00000_0_beta=0.0100,d_thresh=0.0100,obstacle_collision_weight=1.0000,uav_collision_weight=1.0000,use_sa_2023-10-28_22-40-48/error.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "types.RayTaskError(ValueError)(ValueError(\"Expected parameter loc (Tensor of shape (4096, 3)) of distribution Normal(loc: torch.Size([4096, 3]), scale: torch.Size([4096, 3])) to satisfy the constraint Real(), but found invalid values:\\ntensor([[nan, nan, nan],\\n        [nan, nan, nan],\\n        [nan, nan, nan],\\n        ...,\\n        [nan, nan, nan],\\n        [nan, nan, nan],\\n        [nan, nan, nan]], device='cuda:0', grad_fn=<SplitBackward0>)\"))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "types.RayTaskError(ValueError)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'ray.rllib.models.preprocessors.NoPreprocessor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prime/anaconda3/envs/ray26/lib/python3.9/site-packages/gym/spaces/box.py:127: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a number, not 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/prime/Documents/workspace/rl_multi_uav_sim/rl_lib_policy.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bprime-linux/home/prime/Documents/workspace/rl_multi_uav_sim/rl_lib_policy.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m prep \u001b[39m=\u001b[39m get_preprocessor(flatten_space(env\u001b[39m.\u001b[39mobservation_space)[\u001b[39m0\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bprime-linux/home/prime/Documents/workspace/rl_multi_uav_sim/rl_lib_policy.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(prep)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bprime-linux/home/prime/Documents/workspace/rl_multi_uav_sim/rl_lib_policy.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m prep \u001b[39m=\u001b[39m prep(env\u001b[39m.\u001b[39;49mobservation_space[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bprime-linux/home/prime/Documents/workspace/rl_multi_uav_sim/rl_lib_policy.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# print(obs.shape)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bprime-linux/home/prime/Documents/workspace/rl_multi_uav_sim/rl_lib_policy.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(obs)\n",
      "File \u001b[0;32m~/anaconda3/envs/ray26/lib/python3.9/site-packages/ray/rllib/models/preprocessors.py:42\u001b[0m, in \u001b[0;36mPreprocessor.__init__\u001b[0;34m(self, obs_space, options)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_options \u001b[39m=\u001b[39m options\n\u001b[1;32m     41\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_shape(obs_space, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_options)\n\u001b[0;32m---> 42\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_size \u001b[39m=\u001b[39m \u001b[39mint\u001b[39;49m(np\u001b[39m.\u001b[39;49mprod(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshape))\n\u001b[1;32m     43\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_i \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     44\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_obs_for_type_matching \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_obs_space\u001b[39m.\u001b[39msample()\n",
      "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'NoneType'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-29 01:32:58,536\tWARNING worker.py:2037 -- The autoscaler failed with the following error:\n",
      "Terminated with signal 15\n",
      "  File \"/home/prime/anaconda3/envs/ray26/lib/python3.9/site-packages/ray/autoscaler/_private/monitor.py\", line 720, in <module>\n",
      "    monitor.run()\n",
      "  File \"/home/prime/anaconda3/envs/ray26/lib/python3.9/site-packages/ray/autoscaler/_private/monitor.py\", line 595, in run\n",
      "    self._run()\n",
      "  File \"/home/prime/anaconda3/envs/ray26/lib/python3.9/site-packages/ray/autoscaler/_private/monitor.py\", line 449, in _run\n",
      "    time.sleep(AUTOSCALER_UPDATE_INTERVAL_S)\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "env = UavSim()\n",
    "obs, info = env.reset()\n",
    "\n",
    "# RLlib uses preprocessors to implement transforms such as one-hot encoding\n",
    "# and flattening of tuple and dict observations.\n",
    "from networkx import convert_node_labels_to_integers\n",
    "from ray.rllib.models.preprocessors import get_preprocessor\n",
    "from ray.rllib.utils.spaces.space_utils import flatten_space\n",
    "from ray.rllib.utils.numpy import convert_to_numpy\n",
    "\n",
    "prep = get_preprocessor(flatten_space(env.observation_space)[0])\n",
    "print(prep)\n",
    "prep = prep(env.observation_space[0])\n",
    "# print(obs.shape)\n",
    "print(obs)\n",
    "# print(convert_to_numpy(obs[0]))\n",
    "print(prep.transform(obs[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-29 00:54:59,718\tERROR checker.py:262 -- Exception 'dict' object has no attribute 'type' raised on function call without checkin input specs. RLlib will now attempt to check the spec before calling the function again.\n"
     ]
    },
    {
     "ename": "SpecCheckingError",
     "evalue": "input spec validation failed on TorchMLPEncoder.forward, Mismatch found in data element ('obs',), which is a TensorSpec: Expected data type <class 'torch.Tensor'> but found NestedDict.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/ray26/lib/python3.9/site-packages/ray/rllib/core/models/specs/specs_dict.py:130\u001b[0m, in \u001b[0;36mSpecDict.validate\u001b[0;34m(self, data, exact_match)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     spec\u001b[39m.\u001b[39;49mvalidate(data_to_validate)\n\u001b[1;32m    131\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/ray26/lib/python3.9/site-packages/ray/rllib/core/models/specs/specs_base.py:232\u001b[0m, in \u001b[0;36mTensorSpec.validate\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(tensor, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtype):\n\u001b[0;32m--> 232\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(_INVALID_TYPE\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtype, \u001b[39mtype\u001b[39m(tensor)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m))\n\u001b[1;32m    234\u001b[0m shape \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_shape(tensor)\n",
      "\u001b[0;31mValueError\u001b[0m: Expected data type <class 'torch.Tensor'> but found NestedDict",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/ray26/lib/python3.9/site-packages/ray/rllib/core/models/specs/checker.py:172\u001b[0m, in \u001b[0;36m_validate\u001b[0;34m(cls_instance, method, data, spec, filter, tag)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m     spec\u001b[39m.\u001b[39;49mvalidate(data)\n\u001b[1;32m    173\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/ray26/lib/python3.9/site-packages/ray/rllib/core/models/specs/specs_dict.py:132\u001b[0m, in \u001b[0;36mSpecDict.validate\u001b[0;34m(self, data, exact_match)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 132\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    133\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMismatch found in data element \u001b[39m\u001b[39m{\u001b[39;00mspec_name\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwhich is a TensorSpec: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    135\u001b[0m         )\n\u001b[1;32m    136\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(spec, (\u001b[39mtype\u001b[39m, \u001b[39mtuple\u001b[39m)):\n",
      "\u001b[0;31mValueError\u001b[0m: Mismatch found in data element ('obs',), which is a TensorSpec: Expected data type <class 'torch.Tensor'> but found NestedDict",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSpecCheckingError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/prime/Documents/workspace/rl_multi_uav_sim/rl_lib_policy.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bprime-linux/home/prime/Documents/workspace/rl_multi_uav_sim/rl_lib_policy.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m logits, _ \u001b[39m=\u001b[39m shared_policy\u001b[39m.\u001b[39;49mmodel({\u001b[39m\"\u001b[39;49m\u001b[39mobs\u001b[39;49m\u001b[39m\"\u001b[39;49m: obs[\u001b[39m0\u001b[39;49m]})\n",
      "File \u001b[0;32m~/anaconda3/envs/ray26/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/ray26/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ray26/lib/python3.9/site-packages/ray/rllib/core/rl_module/torch/torch_rl_module.py:90\u001b[0m, in \u001b[0;36mTorchRLModule.forward\u001b[0;34m(self, batch, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, batch: Mapping[\u001b[39mstr\u001b[39m, Any], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Mapping[\u001b[39mstr\u001b[39m, Any]:\n\u001b[1;32m     85\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"forward pass of the module.\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \n\u001b[1;32m     87\u001b[0m \u001b[39m    This is aliased to forward_train because Torch DDP requires a forward method to\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[39m    be implemented for backpropagation to work.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward_train(batch, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/ray26/lib/python3.9/site-packages/ray/rllib/core/models/specs/checker.py:257\u001b[0m, in \u001b[0;36mcheck_input_specs.<locals>.decorator.<locals>.wrapper\u001b[0;34m(self, input_data, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39m, input_data, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    256\u001b[0m \u001b[39mexcept\u001b[39;00m SpecCheckingError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 257\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    258\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    259\u001b[0m     \u001b[39m# We store the initial exception to raise it later if the spec\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# check fails.\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     initial_exception \u001b[39m=\u001b[39m e\n",
      "File \u001b[0;32m~/anaconda3/envs/ray26/lib/python3.9/site-packages/ray/rllib/core/models/specs/checker.py:255\u001b[0m, in \u001b[0;36mcheck_input_specs.<locals>.decorator.<locals>.wrapper\u001b[0;34m(self, input_data, **kwargs)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[39mif\u001b[39;00m only_check_on_retry:\n\u001b[1;32m    253\u001b[0m     \u001b[39m# Attempt to run the function without spec checking\u001b[39;00m\n\u001b[1;32m    254\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 255\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, input_data, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    256\u001b[0m     \u001b[39mexcept\u001b[39;00m SpecCheckingError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    257\u001b[0m         \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/anaconda3/envs/ray26/lib/python3.9/site-packages/ray/rllib/core/models/specs/checker.py:359\u001b[0m, in \u001b[0;36mcheck_output_specs.<locals>.decorator.<locals>.wrapper\u001b[0;34m(self, input_data, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[39mif\u001b[39;00m cache \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m__checked_output_specs_cache__\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    357\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__checked_output_specs_cache__ \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 359\u001b[0m output_data \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, input_data, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    361\u001b[0m \u001b[39mif\u001b[39;00m output_specs:\n\u001b[1;32m    362\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, output_specs):\n",
      "File \u001b[0;32m~/anaconda3/envs/ray26/lib/python3.9/site-packages/ray/rllib/core/rl_module/rl_module.py:592\u001b[0m, in \u001b[0;36mRLModule.forward_train\u001b[0;34m(self, batch, **kwargs)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[39m@check_input_specs\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m_input_specs_train\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    578\u001b[0m \u001b[39m@check_output_specs\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m_output_specs_train\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    579\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward_train\u001b[39m(\u001b[39mself\u001b[39m, batch: SampleBatchType, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Mapping[\u001b[39mstr\u001b[39m, Any]:\n\u001b[1;32m    580\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Forward-pass during training called from the learner. This method should\u001b[39;00m\n\u001b[1;32m    581\u001b[0m \u001b[39m    not be overriden. Instead, override the _forward_train method.\u001b[39;00m\n\u001b[1;32m    582\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[39m        ouptut_specs_train().\u001b[39;00m\n\u001b[1;32m    591\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 592\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_train(batch, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/ray26/lib/python3.9/site-packages/ray/rllib/algorithms/ppo/torch/ppo_torch_rl_module.py:62\u001b[0m, in \u001b[0;36mPPOTorchRLModule._forward_train\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     59\u001b[0m output \u001b[39m=\u001b[39m {}\n\u001b[1;32m     61\u001b[0m \u001b[39m# Shared encoder\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m encoder_outs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(batch)\n\u001b[1;32m     63\u001b[0m \u001b[39mif\u001b[39;00m STATE_OUT \u001b[39min\u001b[39;00m encoder_outs:\n\u001b[1;32m     64\u001b[0m     output[STATE_OUT] \u001b[39m=\u001b[39m encoder_outs[STATE_OUT]\n",
      "File \u001b[0;32m~/anaconda3/envs/ray26/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/ray26/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ray26/lib/python3.9/site-packages/ray/rllib/core/models/specs/checker.py:257\u001b[0m, in \u001b[0;36mcheck_input_specs.<locals>.decorator.<locals>.wrapper\u001b[0;34m(self, input_data, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39m, input_data, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    256\u001b[0m \u001b[39mexcept\u001b[39;00m SpecCheckingError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 257\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    258\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    259\u001b[0m     \u001b[39m# We store the initial exception to raise it later if the spec\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# check fails.\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     initial_exception \u001b[39m=\u001b[39m e\n",
      "File \u001b[0;32m~/anaconda3/envs/ray26/lib/python3.9/site-packages/ray/rllib/core/models/specs/checker.py:255\u001b[0m, in \u001b[0;36mcheck_input_specs.<locals>.decorator.<locals>.wrapper\u001b[0;34m(self, input_data, **kwargs)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[39mif\u001b[39;00m only_check_on_retry:\n\u001b[1;32m    253\u001b[0m     \u001b[39m# Attempt to run the function without spec checking\u001b[39;00m\n\u001b[1;32m    254\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 255\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, input_data, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    256\u001b[0m     \u001b[39mexcept\u001b[39;00m SpecCheckingError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    257\u001b[0m         \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/anaconda3/envs/ray26/lib/python3.9/site-packages/ray/rllib/core/models/torch/base.py:120\u001b[0m, in \u001b[0;36mTorchModel.forward\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward(input_data, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m     \u001b[39mreturn\u001b[39;00m checked_forward(\u001b[39mself\u001b[39m, inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 120\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward(inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/ray26/lib/python3.9/site-packages/ray/rllib/core/models/base.py:343\u001b[0m, in \u001b[0;36mActorCriticEncoder._forward\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m    336\u001b[0m         ENCODER_OUT: {\n\u001b[1;32m    337\u001b[0m             ACTOR: encoder_outs[ENCODER_OUT],\n\u001b[1;32m    338\u001b[0m             CRITIC: encoder_outs[ENCODER_OUT],\n\u001b[1;32m    339\u001b[0m         }\n\u001b[1;32m    340\u001b[0m     }\n\u001b[1;32m    341\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    342\u001b[0m     \u001b[39m# Encoders should not modify inputs, so we can pass the same inputs\u001b[39;00m\n\u001b[0;32m--> 343\u001b[0m     actor_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactor_encoder(inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    344\u001b[0m     critic_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcritic_encoder(inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    346\u001b[0m     \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m    347\u001b[0m         ENCODER_OUT: {\n\u001b[1;32m    348\u001b[0m             ACTOR: actor_out[ENCODER_OUT],\n\u001b[1;32m    349\u001b[0m             CRITIC: critic_out[ENCODER_OUT],\n\u001b[1;32m    350\u001b[0m         }\n\u001b[1;32m    351\u001b[0m     }\n",
      "File \u001b[0;32m~/anaconda3/envs/ray26/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/ray26/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ray26/lib/python3.9/site-packages/ray/rllib/core/models/specs/checker.py:280\u001b[0m, in \u001b[0;36mcheck_input_specs.<locals>.decorator.<locals>.wrapper\u001b[0;34m(self, input_data, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mif\u001b[39;00m spec \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     spec \u001b[39m=\u001b[39m convert_to_canonical_format(spec)\n\u001b[0;32m--> 280\u001b[0m     checked_data \u001b[39m=\u001b[39m _validate(\n\u001b[1;32m    281\u001b[0m         cls_instance\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    282\u001b[0m         method\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    283\u001b[0m         data\u001b[39m=\u001b[39;49minput_data,\n\u001b[1;32m    284\u001b[0m         spec\u001b[39m=\u001b[39;49mspec,\n\u001b[1;32m    285\u001b[0m         \u001b[39mfilter\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mfilter\u001b[39;49m,\n\u001b[1;32m    286\u001b[0m         tag\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39minput\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    287\u001b[0m     )\n\u001b[1;32m    289\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mfilter\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(checked_data, NestedDict):\n\u001b[1;32m    290\u001b[0m         \u001b[39m# filtering should happen regardless of cache\u001b[39;00m\n\u001b[1;32m    291\u001b[0m         checked_data \u001b[39m=\u001b[39m checked_data\u001b[39m.\u001b[39mfilter(spec)\n",
      "File \u001b[0;32m~/anaconda3/envs/ray26/lib/python3.9/site-packages/ray/rllib/core/models/specs/checker.py:174\u001b[0m, in \u001b[0;36m_validate\u001b[0;34m(cls_instance, method, data, spec, filter, tag)\u001b[0m\n\u001b[1;32m    172\u001b[0m         spec\u001b[39m.\u001b[39mvalidate(data)\n\u001b[1;32m    173\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 174\u001b[0m         \u001b[39mraise\u001b[39;00m SpecCheckingError(\n\u001b[1;32m    175\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mtag\u001b[39m}\u001b[39;00m\u001b[39m spec validation failed on \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    176\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mcls_instance\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mmethod\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    177\u001b[0m         )\n\u001b[1;32m    179\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "\u001b[0;31mSpecCheckingError\u001b[0m: input spec validation failed on TorchMLPEncoder.forward, Mismatch found in data element ('obs',), which is a TensorSpec: Expected data type <class 'torch.Tensor'> but found NestedDict."
     ]
    }
   ],
   "source": [
    "logits, _ = shared_policy.model({\"obs\": obs[0]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ray26",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
